{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.7.11 64-bit ('mlai': conda)"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.7.11","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"interpreter":{"hash":"35ebf5710b4eabfcdf8f5c83ad104ed5a90d170633efc49a8df212611f0c6cfc"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":["This notebook was built on the notebook shared by [xhlulu](https://www.kaggle.com/xhlulu/real-vs-fake-starter-code)."],"metadata":{}},{"cell_type":"code","execution_count":1,"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"outputs":[],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true}},{"cell_type":"code","execution_count":2,"source":["import cv2\n","import numpy as np\n","from tensorflow.keras import layers\n","from tensorflow.keras.applications import DenseNet121\n","from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import load_model\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics\n","import tensorflow as tf"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":3,"source":["def build_model(pretrained):\n","    model = Sequential([\n","        pretrained,\n","        layers.GlobalAveragePooling2D(),\n","        layers.Dense(1, activation='sigmoid')\n","    ])\n","    \n","    model.compile(\n","        loss='binary_crossentropy',\n","        optimizer=Adam(),\n","        metrics=['accuracy']\n","    )\n","    \n","    return model"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["\n","def plot_loss(epochs, loss, val_loss):\n","    plt.plot(epochs, loss, 'bo', label='Training Loss')\n","    plt.plot(epochs, val_loss, 'orange', label = 'Validation Loss')\n","    plt.title('Training and Validation Loss')\n","    plt.legend()\n","    plt.show()\n","    \n","\n","def plot_accuracy(epochs, acc, val_acc):\n","    plt.plot(epochs, acc, 'bo', label='Training accuracy')\n","    plt.plot(epochs, val_acc, 'orange', label = 'Validation accuracy')\n","    plt.title('Training and Validation Accuracy')\n","    plt.legend()\n","    plt.show()"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# base_path = '../combined-real-and-fake-faces/combined-real-vs-fake/'\n","base_path = '/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake/'\n","image_gen = ImageDataGenerator()\n","\n","train_flow = image_gen.flow_from_directory(\n","    base_path + 'train/',\n","    target_size=(224, 224),\n","    batch_size=64,\n","    color_mode='grayscale',\n","    class_mode='binary'\n",")\n","\n","valid_flow = image_gen.flow_from_directory(\n","    base_path + 'valid/',\n","    target_size=(224, 224),\n","    batch_size=64,\n","    color_mode='grayscale',\n","    class_mode='binary'\n",")\n"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["test_flow = image_gen.flow_from_directory(\n","    base_path + 'test/',\n","    target_size=(224, 224),\n","    batch_size=1,\n","    color_mode='grayscale',\n","    shuffle = False,\n","    class_mode='binary'\n",")"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":4,"source":["densenet = DenseNet121(\n","    weights=None,\n","    include_top=False,\n","    input_shape=(224,224,1)\n",")\n","model = build_model(densenet)\n","model.summary()"],"outputs":[{"output_type":"stream","name":"stderr","text":["2021-09-26 15:49:07.516433: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","densenet121 (Functional)     (None, 7, 7, 1024)        7031232   \n","_________________________________________________________________\n","global_average_pooling2d (Gl (None, 1024)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 1)                 1025      \n","=================================================================\n","Total params: 7,032,257\n","Trainable params: 6,948,609\n","Non-trainable params: 83,648\n","_________________________________________________________________\n"]}],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["train_steps = 100000//64\n","valid_steps = 20000//64\n","\n","history = model.fit_generator(\n","    train_flow,\n","    epochs = 10,\n","    steps_per_epoch = train_steps,\n","    validation_data = valid_flow,\n","    validation_steps = valid_steps \n",")"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["model.save('grayscale_densenet.h5')"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["plot_loss(range(1, len(loss) + 1), loss, val_loss)"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["plot_accuracy(range(1, len(loss) + 1), acc, val_acc)"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["y_pred = model.predict(test_flow)\n","y_test = test_flow.classes"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["print(\"ROC-AUC Score:\", metrics.roc_auc_score(y_test, y_pred))\n","print(\"AP Score:\", metrics.average_precision_score(y_test, y_pred))\n","print()\n","print(metrics.classification_report(y_test, y_pred > 0.5))"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{"trusted":true}}]}