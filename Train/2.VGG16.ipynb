{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.10 64-bit ('aiml': conda)"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"bdb86f148632ff7f21ea53cc1f5e18540d5c72ffdaf5a16b156743d6a8c71e4e"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":["## VGG 16\n","\n","- Checkout [this](https://neurohive.io/en/popular-networks/vgg16/) article for better Explanation."],"metadata":{}},{"cell_type":"code","execution_count":1,"source":["import numpy as np\r\n","import tensorflow as tf\r\n","from tensorflow import keras\r\n","from tensorflow.keras import layers\r\n","from tensorflow.keras.layers import Activation\r\n","from tensorflow.keras.optimizers import Adam\r\n","from tensorflow.keras.metrics import categorical_crossentropy\r\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n","from sklearn.metrics import confusion_matrix\r\n","import itertools\r\n","import os\r\n","import cv2\r\n","from sklearn.model_selection import train_test_split\r\n","import matplotlib.pyplot as plt\r\n","%matplotlib inline\r\n","\r\n","## I don't know why but without running this cell the below code is shown an error. \r\n","## Running all these imports again solved it.\r\n","## Will figure out soon."],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-12T10:31:06.978403Z","iopub.execute_input":"2021-09-12T10:31:06.978764Z","iopub.status.idle":"2021-09-12T10:31:06.992545Z","shell.execute_reply.started":"2021-09-12T10:31:06.978733Z","shell.execute_reply":"2021-09-12T10:31:06.990818Z"},"trusted":true}},{"cell_type":"code","execution_count":2,"source":["\r\n","real = \"archive//real_and_fake_face//training_real\"\r\n","fake = \"archive//real_and_fake_face//training_fake\"\r\n","datadir = \"archive//real_and_fake_face\"\r\n","\r\n","\r\n","real_path = os.listdir(real)\r\n","fake_path = os.listdir(fake)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["training_data = []\r\n","IMG_SIZE = 224\r\n","\r\n","## This means 0 will indicate Real facial Images and 1 to Fake facial Images.\r\n","\r\n","categories = [\"training_real\" , \"training_fake\"]\r\n","\r\n","def create_training_data():\r\n","    for category in categories:\r\n","        path = os.path.join(datadir, category)\r\n","        class_num = categories.index(category)\r\n","        for img in os.listdir(path):\r\n","            try:\r\n","                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_UNCHANGED)\r\n","                new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\r\n","                training_data.append([new_array,class_num])\r\n","            except:\r\n","                pass\r\n","create_training_data()"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":4,"source":["import random\r\n","\r\n","np.random.shuffle(training_data)\r\n","for sample in training_data[:10]:\r\n","    print(sample[1])"],"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","0\n","1\n","0\n","0\n","1\n","0\n","0\n","0\n","0\n"]}],"metadata":{}},{"cell_type":"code","execution_count":5,"source":["X = []\r\n","y = []\r\n","\r\n","for features,label in training_data:\r\n","    X.append(features)\r\n","    y.append(label)\r\n","\r\n","X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\r\n","y = np.array(y)\r\n","X = X/255.0 \r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":6,"source":["\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":7,"source":["train_x = keras.utils.normalize(X_train,axis=1)\r\n","test_x = keras.utils.normalize(X_test, axis=1)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":8,"source":["#vgg16_model = keras.applications.vgg16.VGG16()\r\n","vgg16_model = keras.models.load_model('upgraded_vgg16.h5')\r\n","vgg16_model.summary()"],"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 25088)             0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              102764544 \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","dense (Dense)                (None, 2)                 8194      \n","=================================================================\n","Total params: 134,268,738\n","Trainable params: 8,194\n","Non-trainable params: 134,260,544\n","_________________________________________________________________\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-09-12T10:31:08.771190Z","iopub.execute_input":"2021-09-12T10:31:08.771696Z","iopub.status.idle":"2021-09-12T10:31:29.001408Z","shell.execute_reply.started":"2021-09-12T10:31:08.771648Z","shell.execute_reply":"2021-09-12T10:31:28.998106Z"},"trusted":true}},{"cell_type":"markdown","source":["- **predictions (Dense)          (None, 1000)              4097000**\n","\n","- Vgg-16 is trained for classification of 1000 different classes, but we do not need that.\n","- So we will remove that last layer and add one of our own."],"metadata":{}},{"cell_type":"code","execution_count":9,"source":["type(vgg16_model)\r\n","## This is not a sequential model."],"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensorflow.python.keras.engine.sequential.Sequential"]},"metadata":{},"execution_count":9}],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":11,"source":["vgg16_model.compile(optimizer='adam',\r\n","              loss='sparse_categorical_crossentropy',\r\n","              metrics=['accuracy'])\r\n","\r\n","hist = vgg16_model.fit(X_train,y_train, batch_size=20, epochs = 3, validation_split=0.1)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","74/74 [==============================] - 730s 10s/step - loss: nan - accuracy: 0.5313 - val_loss: nan - val_accuracy: 0.4756\n","Epoch 2/3\n","74/74 [==============================] - 718s 10s/step - loss: nan - accuracy: 0.5313 - val_loss: nan - val_accuracy: 0.4756\n","Epoch 3/3\n","74/74 [==============================] - 716s 10s/step - loss: nan - accuracy: 0.5313 - val_loss: nan - val_accuracy: 0.4756\n"]}],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":12,"source":["vgg16_model.save('./vgg16.model', save_format='h5')"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["epochs = 50\r\n","train_loss = hist.history['loss']\r\n","val_loss = hist.history['val_loss']\r\n","train_acc = hist.history['accuracy']\r\n","val_acc = hist.history['val_accuracy']\r\n","xc = range(epochs)\r\n","\r\n","plt.figure(1,figsize=(7,5))\r\n","plt.plot(xc,train_loss)\r\n","plt.plot(xc,val_loss)\r\n","plt.xlabel('num of Epochs')\r\n","plt.ylabel('loss')\r\n","plt.title('train_loss vs val_loss')\r\n","plt.grid(True)\r\n","plt.legend(['train','val'])\r\n","#print plt.style.available # use bmh, classic,ggplot for big pictures\r\n","plt.style.use(['classic'])\r\n","\r\n","plt.figure(2,figsize=(7,5))\r\n","plt.plot(xc,train_acc)\r\n","plt.plot(xc,val_acc)\r\n","plt.xlabel('num of Epochs')\r\n","plt.ylabel('accuracy')\r\n","plt.title('train_acc vs val_acc')\r\n","plt.grid(True)\r\n","plt.legend(['train','val'],loc=4)\r\n","#print plt.style.available # use bmh, classic,ggplot for big pictures\r\n","plt.style.use(['classic'])"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["val_loss, val_acc = vgg16_model.evaluate(X_test, y_test)\n","print(val_loss)\n","print(val_acc)"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["predictions = vgg16_model.predict(X_test[[0]])\n","# predictions"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["vgg16_model.predict_classes(x = X_test[[0]], verbose=0)\n"],"outputs":[],"metadata":{"trusted":true}}]}